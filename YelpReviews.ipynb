{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YelpReviews.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbtZYlLPsIV6"
      },
      "source": [
        "**Initialization**\n",
        "* I use these 3 lines of code on top of my each Notebooks because it will help to prevent any problems while reloading and reworking on a same Project or Problem. And the third line of code helps to make visualization within the Notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxfmAXrKqdP4"
      },
      "source": [
        "#@ Initialization:\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3_-GPMtsogi"
      },
      "source": [
        "**Downloading the Libraries and Dependencies**\n",
        "* I have downloaded all the Libraries and Dependencies required for this Project in one particular cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOUCz_ptsk5n"
      },
      "source": [
        "#@ Downloading the Libraries and Dependencies:\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re, json, string, os\n",
        "import collections\n",
        "\n",
        "from argparse import Namespace\n",
        "from IPython.display import display \n",
        "from collections import Counter\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqxsGbL2ty77"
      },
      "source": [
        "**Getting the Data**\n",
        "* I have used Google Colab for this Project so the process of downloading and reading the Data might be different in other platforms. I have used [**Yelp Reviews Dataset**](https://www.kaggle.com/yelp-dataset/yelp-dataset) for this Project. In 2015, Yelp held a contest to predict the Rating of the Restaurants given it's Reviews. Zhang, Zhao, and Lecun simplified the Dataset by converting the Ratings into Sentiments viz. Positive Sentiment for 3 to 4 star Ratings and Negative Sentiment for 1 to 2 star Ratings. The Dataset is splitted into 560,000 Training Samples and 38,000 Testing Samples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEf2bLPctxxl",
        "outputId": "7c9db35a-a947-42d9-ea4b-fb5f2814b4fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#@ Getting the Dataset:\n",
        "args = Namespace(\n",
        "    raw_train_dataset = \"/content/drive/My Drive/Colab Notebooks/YELP Dataset/raw_train.csv\",\n",
        "    raw_test_dataset = \"/content/drive/My Drive/Colab Notebooks/YELP Dataset/raw_test.csv\",\n",
        "    proportion_subset_of_train = 0.1,\n",
        "    train_proportion = 0.7,\n",
        "    val_proportion = 0.15,\n",
        "    test_proportion = 0.15,   \n",
        "    output_munged = \"/content/drive/My Drive/Colab Notebooks/YELP Dataset/reviews_with_splits_lite.csv\",\n",
        "    seed = 1337\n",
        ")\n",
        "\n",
        "#@ Reading the Raw Dataset:\n",
        "train_reviews = pd.read_csv(args.raw_train_dataset, header=None, names=[\"rating\", \"review\"])\n",
        "train_reviews = train_reviews[~pd.isnull(train_reviews.review)]\n",
        "test_reviews = pd.read_csv(args.raw_test_dataset, header=None, names=[\"rating\", \"review\"])\n",
        "test_reviews = test_reviews[~pd.isnull(test_reviews.review)]\n",
        "\n",
        "#@ Inspecting the DataFrame:\n",
        "display(train_reviews.head())\n",
        "print(\" \")\n",
        "display(test_reviews.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>I'm writing this review to give you a heads up...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>All the food is great here. But the best thing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                             review\n",
              "0       1  Unfortunately, the frustration of being Dr. Go...\n",
              "1       2  Been going to Dr. Goldberg for over 10 years. ...\n",
              "2       1  I don't know what Dr. Goldberg was like before...\n",
              "3       1  I'm writing this review to give you a heads up...\n",
              "4       2  All the food is great here. But the best thing..."
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Ordered a large Mango-Pineapple smoothie. Stay...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Quite a surprise!  \\n\\nMy wife and I loved thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>First I will say, this is a nice atmosphere an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>I was overall pretty impressed by this hotel. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Video link at bottom review. Worst service I h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                             review\n",
              "0       1  Ordered a large Mango-Pineapple smoothie. Stay...\n",
              "1       2  Quite a surprise!  \\n\\nMy wife and I loved thi...\n",
              "2       1  First I will say, this is a nice atmosphere an...\n",
              "3       2  I was overall pretty impressed by this hotel. ...\n",
              "4       1  Video link at bottom review. Worst service I h..."
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXy2fNnm6B2G"
      },
      "source": [
        "**Processing the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mJggX9i6pPu",
        "outputId": "c35a2e3d-66dc-4d4d-fd02-bfcf72ae452c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#@ Creating the Subset of the Reviews Dataset:\n",
        "by_rating = collections.defaultdict(list)                     # Collections stores the collection of Data.\n",
        "for _, row in train_reviews.iterrows():\n",
        "  by_rating[row.rating].append(row.to_dict())\n",
        "\n",
        "review_subset = []\n",
        "for _, item_list in sorted(by_rating.items()):\n",
        "  n_total = len(item_list)\n",
        "  n_subset = int(args.proportion_subset_of_train * n_total)\n",
        "  review_subset.extend(item_list[:n_subset])\n",
        "\n",
        "#@ Creating the DataFrame:\n",
        "review_subset = pd.DataFrame(review_subset)\n",
        "\n",
        "#@ Inspecting the DataFrame:\n",
        "review_subset.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>I'm writing this review to give you a heads up...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Wing sauce is like water. Pretty much a lot of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Owning a driving range inside the city limits ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                             review\n",
              "0       1  Unfortunately, the frustration of being Dr. Go...\n",
              "1       1  I don't know what Dr. Goldberg was like before...\n",
              "2       1  I'm writing this review to give you a heads up...\n",
              "3       1  Wing sauce is like water. Pretty much a lot of...\n",
              "4       1  Owning a driving range inside the city limits ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-7B4BjjC4lx",
        "outputId": "19cc7ab0-abf0-4cb1-dd70-7ffc91d3cb98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#@ Performing the Basic EDA:\n",
        "display(train_reviews.rating.value_counts())                   # Inspecting the Number of Ratings.\n",
        "print(\" \")\n",
        "display(review_subset.rating.value_counts())                   # Inspecting the Number of Ratings.\n",
        "print(\" \")\n",
        "display(set(review_subset.rating))                             # Unique Ratings in the DataFrame."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2    280000\n",
              "1    280000\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2    28000\n",
              "1    28000\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{1, 2}"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "putltJH7EoXk"
      },
      "source": [
        "**Processing the DataFrame**\n",
        "* Creating Training, Validation and Testing Splits in the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4s7Lqo3EPCw",
        "outputId": "61c86c4e-867b-4330-9b27-64d31d93ba6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#@ Splitting the Subset by Rating to create New Training, Validation and Testing Splits:\n",
        "by_rating = collections.defaultdict(list)\n",
        "for _, row in review_subset.iterrows():\n",
        "  by_rating[row.rating].append(row.to_dict())\n",
        "\n",
        "#@ Creating the Split Data:\n",
        "final_list = []\n",
        "np.random.seed(args.seed)\n",
        "for _, item_list in sorted(by_rating.items()):\n",
        "  np.random.shuffle(item_list)                                     # Shuffling the Data randomly.\n",
        "  n_total = len(item_list)\n",
        "  n_train = int(args.train_proportion * n_total)\n",
        "  n_val = int(args.val_proportion * n_total)\n",
        "  n_test = int(args.test_proportion * n_total)\n",
        "  #@ Giving the Data point a split Attribute:\n",
        "  for item in item_list[:n_train]:\n",
        "    item[\"split\"] = \"train\"\n",
        "  for item in item_list[n_train:n_train+n_val]:\n",
        "    item[\"split\"] = \"val\"\n",
        "  for item in item_list[n_train+n_val:n_train+n_val+n_test]:\n",
        "    item[\"split\"] = \"test\" \n",
        "  #@ Adding to the Final List:\n",
        "  final_list.extend(item_list)\n",
        "\n",
        "#@ Creating the Final DataFrame:\n",
        "final_reviews = pd.DataFrame(final_list)\n",
        "\n",
        "#@ Inspecting the Final Result:\n",
        "display(final_reviews.head())                                     # Inspecting the DataFrame.\n",
        "print(\" \")\n",
        "display(final_reviews.split.value_counts())                       # Inspecting the Training, Validation and Testing Data."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Terrible place to work for I just heard a stor...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3 hours, 15 minutes-- total time for an extrem...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>My less than stellar review is for service.   ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>I'm granting one star because there's no way t...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>The food here is mediocre at best. I went afte...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                             review  split\n",
              "0       1  Terrible place to work for I just heard a stor...  train\n",
              "1       1  3 hours, 15 minutes-- total time for an extrem...  train\n",
              "2       1  My less than stellar review is for service.   ...  train\n",
              "3       1  I'm granting one star because there's no way t...  train\n",
              "4       1  The food here is mediocre at best. I went afte...  train"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train    39200\n",
              "val       8400\n",
              "test      8400\n",
              "Name: split, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf1YXxrhMoo6"
      },
      "source": [
        "**Cleaning the Data**\n",
        "* I will clean the Data minimally by adding whitespace around Punctuation symbols and Removing Extraneous symbols which are not Punctuations for all the Splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ZIg3tvL7jB",
        "outputId": "d19db0d5-1791-4185-e33c-cc3508687de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "#@ Cleaning the Data:\n",
        "def preprocess_text(text):\n",
        "  text = text.lower()                                      # Converting into Lowercase.\n",
        "  text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
        "  text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
        "  return text\n",
        "\n",
        "#@ Processing the Review Column:\n",
        "final_reviews[\"review\"] = final_reviews.review.apply(preprocess_text)\n",
        "\n",
        "#@ Processing the Rating Column:\n",
        "final_reviews[\"rating\"] = final_reviews.rating.apply({1:\"negative\", 2:\"positive\"}.get)\n",
        "\n",
        "#@ Inspecting the DataFrame:\n",
        "final_reviews.head(7)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>terrible place to work for i just heard a stor...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>hours , minutes total time for an extremely s...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>my less than stellar review is for service . w...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>i m granting one star because there s no way t...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>the food here is mediocre at best . i went aft...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>negative</td>\n",
              "      <td>n n nwe looked at our entertainment book for ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>negative</td>\n",
              "      <td>i had an appointment that was made months in a...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     rating                                             review  split\n",
              "0  negative  terrible place to work for i just heard a stor...  train\n",
              "1  negative   hours , minutes total time for an extremely s...  train\n",
              "2  negative  my less than stellar review is for service . w...  train\n",
              "3  negative  i m granting one star because there s no way t...  train\n",
              "4  negative  the food here is mediocre at best . i went aft...  train\n",
              "5  negative   n n nwe looked at our entertainment book for ...  train\n",
              "6  negative  i had an appointment that was made months in a...  train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ3bDFXcPS5s"
      },
      "source": [
        "#@ Preparing the Data:\n",
        "final_reviews.to_csv(args.output_munged, index=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1yeCON1Uvrh"
      },
      "source": [
        "**PyTorch Dataset Class**\n",
        "* PyTorch provides an abstraction for the Dataset by providing a Dataset Class. The Dataset Class is an abstract Operator. When using PyTorch with a new Dataset it is necessary to sub class the Dataset Class and Implement the __getitem__ and __len__ methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c48xIUDyV1UF"
      },
      "source": [
        "#@ PyTorch Dataset Class:\n",
        "class ReviewDataset(Dataset):\n",
        "  def __init__(self, review_df, vectorizer):\n",
        "    \"\"\"\n",
        "    Args: review_df(pandas.DataFrame): The dataset.\n",
        "        : vectorizer(ReviewVectorizer): Vector instantiated from dataset.\n",
        "    \"\"\"\n",
        "    self.review_df = review_df\n",
        "    self._vectorizer = vectorizer\n",
        "\n",
        "    self.train_df = self.review_df[self.review_df.split == \"train\"]\n",
        "    self.train_size = len(self.train_df)\n",
        "\n",
        "    self.val_df = self.review_df[self.review_df.split == \"val\"]\n",
        "    self.validation_size = len(self.val_df)\n",
        "\n",
        "    self.test_df = self.review_df[self.review_df.split == \"test\"]\n",
        "    self.test_size = len(self.test_df)\n",
        "\n",
        "    self._lookup_dict = {\"train\": (self.train_df, self.train_size),\n",
        "                           \"val\": (self.val_df, self.validation_size),\n",
        "                           \"test\": (self.test_df, self.test_size)}\n",
        "    self.set_split(\"train\")\n",
        "  \n",
        "  @classmethod\n",
        "  def load_dataset_and_make_vectorizer(cls, review_csv):\n",
        "    \"\"\"Load dataset and make new vectorizer from scratch.\n",
        "    Args: review_csv: Location of the dataset.\n",
        "    Returns: An instance of ReviewDataset.\n",
        "    \"\"\"\n",
        "    review_df = pd.read_csv(review_csv)\n",
        "    train_review_df = review_df[review_df.split == \"train\"]\n",
        "    return cls(review_df, ReviewVectorizer.from_datafram(train_review_df))\n",
        "  \n",
        "  @classmethod\n",
        "  def load_dataset_and_load_vectorizer(cls, review_csv, vectorizer_filepath):\n",
        "    \"\"\"Load dataset and the corresponding vectorizer.\n",
        "    Args: review_csv: Location of the dataset.\n",
        "        : vectorizer_filepath: Location of the saved vectorizer.\n",
        "    Returns: An instance of the ReviewDataset.\n",
        "    \"\"\"\n",
        "    review_df = pd.read_csv(review_csv)\n",
        "    vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
        "    return cls(review_df, vectorizer)\n",
        "\n",
        "  @staticmethod\n",
        "  def load_vectorizer_only(vectorizer_filepath):\n",
        "    \"\"\"A static method for loading the vectorizer from file.\n",
        "    Args: vectorizer_filepath: Location of serialized vectorizer.\n",
        "    Returns: An instance of ReviewVectorizer.\n",
        "    \"\"\"\n",
        "    with open(vectorizer_filepath, \"w\") as fp:\n",
        "      json.dump(self._vectorizer.to_serializable(), fp)\n",
        "  \n",
        "  def get_vectorizer(self):\n",
        "    \"\"\"Returns the Vectorizer.\n",
        "    \"\"\"\n",
        "    return self._vectorizer\n",
        "  \n",
        "  def set_split(self, split=\"train\"):\n",
        "    \"\"\"Splits the dataset using a column in the DataFrame.\n",
        "    Args: split(str): One of \"train\", \"val\" or \"test\"\n",
        "    \"\"\"\n",
        "    self._target_split = split\n",
        "    self._target_df, self._target_size = self._lookup_dict[split]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self._target_size\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"Primary entry point of PyTorch Datasets.\n",
        "    Args: index: Index of the Datapoint.\n",
        "    Returns: A dictionary holding the Data point features and labels.\n",
        "    \"\"\"\n",
        "    row = self._target_df.iloc[index]\n",
        "    review_vector = self._vectorizer.vectorize(row.review)\n",
        "    rating_index = self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
        "    return {\"x_data\": review_vector,\n",
        "            \"y_target\": rating_index}\n",
        "  \n",
        "  def get_num_batches(self, batch_size):\n",
        "    \"\"\"Given a batch size, return the number of batches in the Dataset.\n",
        "    Args: batch_size(int)\n",
        "    Returns: Number of batches in the Dataset.\n",
        "    \"\"\"\n",
        "    return len(self) // batch_size"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkPzMtENrNov"
      },
      "source": [
        "**The Vocabulary Class**\n",
        "* The Vocabulary Class not only manages the Bijection i.e Allowing user to add new Tokens and have the Index auto increment but also handles the special token called UNK which stands for Unknown. By using the UNK Token, It will be easy to handle Tokens at Test time that were never seen in Training Instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pNlTVemoILm"
      },
      "source": [
        "#@ The Vocabulary Class:\n",
        "class Vocabulary(object):\n",
        "  \"\"\"Class to process Text and and extract Vocabulary for mapping.\n",
        "  \"\"\"\n",
        "  def __init__(self, token_to_idx=None, add_unk=True, unk_token=\"<UNK>\"):\n",
        "    \"\"\"\n",
        "    Args: token_to_idx(dict): Pre existing map of Tokens to Index.\n",
        "        : add_unk(bool): A flag indicating whether to add UNK Token.\n",
        "        : unk_token(string): The UNK Token to add in Vocabulary.\n",
        "    \"\"\"\n",
        "    if token_to_idx is None:\n",
        "      token_to_idx = {}\n",
        "    self.token_to_idx = token_to_idx\n",
        "    self._idx_to_token = {idx:token for token,idx in self._idx_to_token.items()}\n",
        "    self._add_unk = add_unk\n",
        "    self._unk_token = unk_token\n",
        "    self.unk_index = -1\n",
        "    if add_unk:\n",
        "      self.unk_index = self.add_token(unk_token)\n",
        "  \n",
        "  def to_serializable(self):\n",
        "    \"\"\"Returns a dictionary that can be serialized.\n",
        "    \"\"\"\n",
        "    return {\"token_to_idx\": self._token_to_index,\n",
        "            \"add_unk\": self._add_unk,\n",
        "            \"unk_token\": self._unk_token}\n",
        "  \n",
        "  @classmethod\n",
        "  def from_serializable(cls, contents):\n",
        "    \"\"\"Instantiate the Vocabulary from the serialized Dictionary.\n",
        "    \"\"\"\n",
        "    return cls(**contents)\n",
        "  \n",
        "  def add_token(self, token):\n",
        "    \"\"\"Update the mapping dictionary based on the Tokens.\n",
        "    Args: token: The item to add into the Vocabulary.\n",
        "    Returns: index: Integer corresponding to the Token.\n",
        "    \"\"\"\n",
        "    if token in self._token_to_idx:\n",
        "      index = self._token_to_idx[token]\n",
        "    else:\n",
        "      index = len(self._token_to_idx)\n",
        "      self._token_to_idx[token] = index\n",
        "      self._idx_to_token[index] = token\n",
        "    return index\n",
        "  \n",
        "  def add_many(self, tokens):\n",
        "    \"\"\"Add a list of Tokens into Vocabulary.\n",
        "    Args: tokens(list): A list of string Tokens.\n",
        "    Returns: indices(list): A list of indices correspoinding to the Tokens.\n",
        "    \"\"\"\n",
        "    return [self.add_token(token) for token in tokens]\n",
        "  \n",
        "  def lookup_token(self, token):\n",
        "    \"\"\"Retrieve the Index associated with the Token.\n",
        "    Args: token(str): The Token to lookup.\n",
        "    Returns: index(int): The Index correspoinding to the Token.\n",
        "    \"\"\"\n",
        "    if self.unk_index >= 0:\n",
        "      return self._token_to_idx.get(token, self.unk_index)\n",
        "    else:\n",
        "      return self._token_to_idx[token]\n",
        "  \n",
        "  def lookup_index(self, index):\n",
        "    \"\"\"Return the Token associated with the Index.\n",
        "    Args: index(int): The Index to lookup.\n",
        "    Returns: token(str): The Token correspoinding to the Index.\n",
        "    \"\"\"\n",
        "    if index not in self._idx_to_token:\n",
        "      raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "    return self._idx_to_token[index]\n",
        "  \n",
        "  def __str__(self):\n",
        "    return \"<Vocabulary(size=%d)>\" % len(self)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self._token_to_idx)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmo5yvPYwjEk"
      },
      "source": [
        "**Vectorizer Class**\n",
        "* The second stage of going from a Text Dataset to a vectorized minibatch is to iterate through the Tokens of an Input Data Point and convert each Token to its Integer form. The result of this iteration should be a Vector. Because this Vector will be combined with Vectors from other Data points, there is Constraint that the Vectors produced by the Vectorizer should always have the same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFTiHIgltrHW"
      },
      "source": [
        "#@ Vectorizer Class:\n",
        "class ReviewVectorizer(object):\n",
        "  \"\"\"The Vectorizer coordinates the Vocabularies and puts them to use.\n",
        "  \"\"\"\n",
        "  def __init__(self, review_vocab, rating_vocab):\n",
        "    \"\"\"\n",
        "    Args: review_vocab: Maps words to Integers.\n",
        "        : rating_vocab: Maps class labels to Integers.\n",
        "    \"\"\"\n",
        "    self.review_vocab = review_vocab\n",
        "    self.rating_vocab = rating_vocab\n",
        "\n",
        "  def vectorize(self, review):\n",
        "    \"\"\"Create a collasped Onehot Vector for the review.\n",
        "    Args: review: The review\n",
        "    Returns: one_hot: The collapsed one hot Encoding.\n",
        "    \"\"\"\n",
        "    one_hot = np.zeros(len(self.review_vocab), dtype=np.float32)\n",
        "    for token in review.split(\" \"):\n",
        "      if token not in string.punctuation:\n",
        "        one_hot[self.review_vocab.lookup_token(token)] = 1\n",
        "    return one_hot\n",
        "\n",
        "  @classmethod\n",
        "  def from_dataframe(cls, review_df, cutoff=25):\n",
        "    \"\"\"Instantiate the Vectorizer from DataFrame.\n",
        "    Args: review_df(DataFrame): The review Dataset.\n",
        "        :  cufoff(int): Parameter for frequency based Filtering.\n",
        "    Returns: An instance of the ReviewVectorizer.\n",
        "    \"\"\"\n",
        "    review_vocab = Vocabulary(add_unk=True)\n",
        "    rating_vocab = Vocabulary(add_unk=False)\n",
        "    #@ Adding Ratings:\n",
        "    for rating in sorted(set(review_df.rating)):\n",
        "      rating_vocab.add_token(rating)\n",
        "    #@ Adding Topwords if count > provided count:\n",
        "    word_counts = Counter()\n",
        "    for review in review_df.review:\n",
        "      for word in review.split(\" \"):\n",
        "        if word not in string.punctuation:\n",
        "          word_counts[word] += 1\n",
        "    for word, count in word_counts.items():\n",
        "      if count > cutoff:\n",
        "        review_vocab.add_token(word)\n",
        "    return cls(review_vocab, rating_vocab)\n",
        "\n",
        "  @classmethod\n",
        "  def from_serializable(cls, contents):\n",
        "    \"\"\"Instantiating the ReviewVectorizer from a serializable dictionary.\n",
        "    Args: contents: The serializable dictionary.\n",
        "    Returns: An instance of ReviewVectorizer Class.\n",
        "    \"\"\"\n",
        "    review_vocab = Vocabulary.from_serializable(contents[\"review_vocab\"])\n",
        "    rating_vocab = Vocabulary.from_serializable(contents[\"rating_vocab\"])\n",
        "    return cls(review_vocab=review_vocab, rating_vocab=rating_vocab)\n",
        "  \n",
        "  def to_serializable(self):\n",
        "    \"\"\"Create serializable dictionary for Caching.\n",
        "    Returns: contents(dict): The Serializable Dictionary.\n",
        "    \"\"\"\n",
        "    return {\"review_vocab\": self.review_vocab.to_serializable(),\n",
        "            \"rating_vocab\": self.rating_vocab.to_serializable()}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpZzEdSL90p3"
      },
      "source": [
        "**DataLoader**\n",
        "* The Final step of Text to Vectorized minibatch pipeline is to actually group the Vectorized Datapoints. Because grouping into mini batches is a viatal part of Training the Neural Networks, PyTorch provides a built in class called DataLoader for coordinating the Process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9h1RTS5-wJa"
      },
      "source": [
        "#@ DataLoader:\n",
        "def generate_batches(dataset, batch_size, shuffle=True, \n",
        "                     drop_last=True, device=\"gpu\"):\n",
        "  \"\"\"A generator function which wraps the PyTorch DataLoader. \n",
        "  \"\"\"\n",
        "  dataloader = DataLoader(dataset=dataset, batch_size=batch_size, \n",
        "                          shuffle=shuffle, drop_last=drop_last)\n",
        "  for data_dict in dataloader:\n",
        "    out_data_dict = {}\n",
        "    for name, tensor in data_dict.items():\n",
        "      out_data_dict[name] = data_dict[name].to(device)\n",
        "    yield out_data_dict"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}